{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional\n",
    "import torch\n",
    "import random\n",
    "import os \n",
    "\n",
    "from typing import (\n",
    "    Any,\n",
    "    Callable,\n",
    "    Dict,\n",
    "    Hashable,\n",
    "    Iterable,\n",
    "    List,\n",
    "    Optional,\n",
    "    Sequence,\n",
    "    Tuple,\n",
    "    Type,\n",
    "    TypeVar,\n",
    "    Union,\n",
    ")\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from botorch.models.gp_regression import SingleTaskGP\n",
    "from tqdm import tqdm\n",
    "from torch import Tensor\n",
    "from botorch.acquisition.active_learning import (\n",
    "    MCSampler,\n",
    "    qNegIntegratedPosteriorVariance,\n",
    ")\n",
    "\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from sklearn.model_selection import train_test_split\n",
    "from botorch.models.gp_regression import SingleTaskGP\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import warnings\n",
    "\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\", category=botorch.exceptions.BotorchWarning)\n",
    "\n",
    "from botorch.exceptions.warnings import BotorchTensorDimensionWarning, InputDataWarning\n",
    "warnings.filterwarnings(\n",
    "            \"ignore\",\n",
    "            message=\"Input data is not standardized.\",\n",
    "            category=InputDataWarning,\n",
    "        )\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "from botorch.models.fully_bayesian import SaasFullyBayesianSingleTaskGP\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "from botorch.acquisition.active_learning import (\n",
    "    MCSampler,\n",
    "    qNegIntegratedPosteriorVariance,\n",
    ")\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.double\n",
    "\n",
    "\n",
    "seeds = np.load('seeds.npy')\n",
    "xtest = np.load('xtest.npy')\n",
    "ytest = np.load('ytest.npy')\n",
    "\n",
    "with open('xcandidates_original.pkl', 'rb') as f:\n",
    "    xcandidates_original = pickle.load(f)\n",
    "    \n",
    "with open('ycandidates_original.pkl', 'rb') as f:\n",
    "    ycandidates_original = pickle.load(f)\n",
    "    \n",
    "xtest = torch.tensor(xtest, dtype=dtype,device=device)\n",
    "ytest = torch.tensor(ytest, dtype=dtype,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xcandidates_original)\n",
    "# len(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:45<00:00,  3.46s/it]\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict, Optional\n",
    "import torch\n",
    "import random\n",
    "import os \n",
    "\n",
    "from typing import (\n",
    "    Any,\n",
    "    Callable,\n",
    "    Dict,\n",
    "    Hashable,\n",
    "    Iterable,\n",
    "    List,\n",
    "    Optional,\n",
    "    Sequence,\n",
    "    Tuple,\n",
    "    Type,\n",
    "    TypeVar,\n",
    "    Union,\n",
    ")\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from botorch.models.gp_regression import SingleTaskGP\n",
    "from tqdm import tqdm\n",
    "from torch import Tensor\n",
    "from botorch.acquisition.active_learning import (\n",
    "    MCSampler,\n",
    "    qNegIntegratedPosteriorVariance,\n",
    ")\n",
    "\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from sklearn.model_selection import train_test_split\n",
    "from botorch.models.gp_regression import SingleTaskGP\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import warnings\n",
    "\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\", category=botorch.exceptions.BotorchWarning)\n",
    "\n",
    "from botorch.exceptions.warnings import BotorchTensorDimensionWarning, InputDataWarning\n",
    "warnings.filterwarnings(\n",
    "            \"ignore\",\n",
    "            message=\"Input data is not standardized.\",\n",
    "            category=InputDataWarning,\n",
    "        )\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "from botorch.models.fully_bayesian import SaasFullyBayesianSingleTaskGP\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "from botorch.acquisition.active_learning import (\n",
    "    MCSampler,\n",
    "    qNegIntegratedPosteriorVariance,\n",
    ")\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.double\n",
    "\n",
    "\n",
    "seeds = np.load('seeds.npy')\n",
    "xtest = np.load('xtest.npy')\n",
    "ytest = np.load('ytest.npy')\n",
    "\n",
    "\n",
    "with open('xcandidates_original.pkl', 'rb') as f:\n",
    "    xcandidates_original = pickle.load(f)\n",
    "    \n",
    "with open('ycandidates_original.pkl', 'rb') as f:\n",
    "    ycandidates_original = pickle.load(f)\n",
    "    \n",
    "xtest = torch.tensor(xtest, dtype=dtype,device=device)\n",
    "ytest = torch.tensor(ytest, dtype=dtype,device=device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def random_initial_data(x, y, initial_percent, seed):\n",
    "    np.random.seed(seed)\n",
    "    n = int(len(x)*initial_percent)\n",
    "    idx = np.random.choice(len(x), n, replace=False).tolist()\n",
    "    x_initial = [x[i] for i in idx]\n",
    "    y_initial = [y[i] for i in idx]\n",
    "    xcandidates = [x[i] for i in range(len(x)) if i not in idx]\n",
    "    ycandidates = [y[i] for i in range(len(y)) if i not in idx]\n",
    "    \n",
    "    return x_initial, y_initial, xcandidates, ycandidates\n",
    "\n",
    "uncr_mae_runs = []\n",
    "\n",
    "timing_per_iteration = []\n",
    "timing_per_run = []\n",
    "\n",
    "for seed in seeds[:1]:\n",
    "    # random.seed(seed)\n",
    "    iteration_times = []\n",
    "    uncr_pred_mae = []\n",
    "    uncr_pred_std = []\n",
    "    uncr_pred_mean = []\n",
    "    \n",
    "    xcandidates_uncr = xcandidates_original.copy()\n",
    "    ycandidates_uncr = ycandidates_original.copy()\n",
    "    \n",
    "    \n",
    "    xinit, yinit, xcandidates, ycandidates = random_initial_data(xcandidates_uncr, ycandidates_uncr, 0.05, seed=seed)\n",
    "    \n",
    "\n",
    "    \n",
    "    xinit = torch.cat(xinit,dim=0).to(device)\n",
    "    yinit = torch.cat(yinit,dim=0).to(device)\n",
    "\n",
    "    \n",
    "    gp = SingleTaskGP(xinit, yinit).to(device)\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp).to(device)\n",
    "    fit_gpytorch_mll(mll)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Predict on the test set initially\n",
    "    uncr_ypred = gp(xtest)\n",
    "    uncr_ypred_mean = uncr_ypred.mean.detach().numpy()\n",
    "    # uncr_pred_mean.append(uncr_ypred_mean)\n",
    "    \n",
    "    uncr_ymae = mean_absolute_error(ytest, uncr_ypred_mean)\n",
    "    \n",
    "    uncr_pred_mae.append(uncr_ymae)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(100)):\n",
    "    # for inner_i in tqdm(range(len(xcandidates))):\n",
    "        start_time = time.time()\n",
    "        if not xcandidates:\n",
    "            break\n",
    "        \n",
    "        uncertainties_list = []\n",
    "        for i, candidate_tensor in enumerate(xcandidates):\n",
    "            # Get posterior for this tensor\n",
    "            posterior = gp(candidate_tensor)\n",
    "            # Calculate mean uncertainty for this tensor\n",
    "            tensor_uncertainty = posterior.stddev.mean().detach().numpy()\n",
    "            uncertainties_list.append(tensor_uncertainty)\n",
    "    \n",
    "    # Convert list to numpy array for argmax\n",
    "        uncertainties = np.array(uncertainties_list)\n",
    "        \n",
    "        # posterior_candidates = gp([i for i in xcandidates])\n",
    "        \n",
    "        # uncertainties = [posterior_candidates.stddev.detach().numpy() for i in posterior_candidates]  \n",
    "\n",
    "        # Find the index of the candidate point with the highest uncertainty\n",
    "        max_uncertainty_idx = uncertainties.argmax()\n",
    "        \n",
    "        xinit= torch.cat((xinit, xcandidates[max_uncertainty_idx]), 0).to(device)\n",
    "        yinit = torch.cat((yinit, ycandidates[max_uncertainty_idx]), 0).to(device)\n",
    "        \n",
    "        # print('len of new train:', len(xtrain_rand))\n",
    "        del xcandidates[max_uncertainty_idx]\n",
    "        del ycandidates[max_uncertainty_idx]\n",
    "        \n",
    "        gp = SingleTaskGP(xinit, yinit).to(device)\n",
    "        mll = ExactMarginalLogLikelihood(gp.likelihood, gp).to(device)\n",
    "        fit_gpytorch_mll(mll)\n",
    "        \n",
    "        uncr_ypred = gp(xtest)\n",
    "        uncr_ypred_mean = uncr_ypred.mean.detach().numpy()\n",
    "        \n",
    "        uncr_ymae = mean_absolute_error(ytest, uncr_ypred_mean)\n",
    "        uncr_pred_mae.append(uncr_ymae)\n",
    "        \n",
    "        end_time = time.time()  # End timing\n",
    "        iteration_time = end_time - start_time\n",
    "        iteration_times.append(iteration_time)\n",
    "        \n",
    "    timing_per_run.append(iteration_times)\n",
    "    uncr_mae_runs.append(uncr_pred_mae)\n",
    "    \n",
    "    # np.save('uncr_nmr_runs.npy', np.array(uncr_mae_runs))\n",
    "    np.save('timing_uncertainty_nmr.npy', np.array(timing_per_run))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qbc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
