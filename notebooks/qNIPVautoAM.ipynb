{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standard imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "from botorch.models.gp_regression import SingleTaskGP\n",
    "from tqdm import tqdm\n",
    "from botorch.acquisition.active_learning import qNegIntegratedPosteriorVariance\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.utils.transforms import normalize, standardize\n",
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "from botorch.exceptions.warnings import InputDataWarning\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"Input data is not standardized.\",\n",
    "    category=InputDataWarning,\n",
    ")\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking my working directory so i can make sure to import my data file correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prime Delay</th>\n",
       "      <th>Print Speed</th>\n",
       "      <th>X Offset Correction</th>\n",
       "      <th>Y Offset Correction</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.339554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.218576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999931</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.368919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.070133</td>\n",
       "      <td>0.225151</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.742365</td>\n",
       "      <td>1.714610</td>\n",
       "      <td>-0.380317</td>\n",
       "      <td>-0.416497</td>\n",
       "      <td>0.829756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.585934</td>\n",
       "      <td>-0.337143</td>\n",
       "      <td>-0.372811</td>\n",
       "      <td>0.922120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.568030</td>\n",
       "      <td>-0.335316</td>\n",
       "      <td>-0.365804</td>\n",
       "      <td>0.901296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.558826</td>\n",
       "      <td>-0.349834</td>\n",
       "      <td>-0.328645</td>\n",
       "      <td>0.936549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.837488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prime Delay  Print Speed  X Offset Correction  Y Offset Correction  \\\n",
       "0      0.000000     1.000000             0.000000             0.000000   \n",
       "1      2.500000     3.000000             0.100000             0.100000   \n",
       "2      5.000000     5.000000            -0.100000            -0.100000   \n",
       "3      0.000000     0.999931             0.000006             0.000025   \n",
       "4      0.000000     5.070133             0.225151             1.000000   \n",
       "..          ...          ...                  ...                  ...   \n",
       "95     0.742365     1.714610            -0.380317            -0.416497   \n",
       "96     0.000000     1.585934            -0.337143            -0.372811   \n",
       "97     0.000000     1.568030            -0.335316            -0.365804   \n",
       "98     0.000000     1.558826            -0.349834            -0.328645   \n",
       "99     5.000000     3.837488             1.000000             1.000000   \n",
       "\n",
       "       Score  \n",
       "0   0.339554  \n",
       "1   0.000000  \n",
       "2   0.218576  \n",
       "3   0.368919  \n",
       "4   0.000000  \n",
       "..       ...  \n",
       "95  0.829756  \n",
       "96  0.922120  \n",
       "97  0.901296  \n",
       "98  0.936549  \n",
       "99  0.000000  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/AutoAM_dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converting my data into a tensor / and normalizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlower_bounds = []\n",
    "xupper_bounds = []\n",
    "x_vals = df.iloc[:,:-1]\n",
    "for col in x_vals.columns:\n",
    "    xlower = x_vals[col].min()\n",
    "    xupper = x_vals[col].max()\n",
    "    xlower_bounds.append(xlower)\n",
    "    xupper_bounds.append(xupper)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlower_bounds = torch.tensor(xlower_bounds, dtype=torch.double)\n",
    "xupper_bounds = torch.tensor(xupper_bounds, dtype=torch.double)\n",
    "\n",
    "xbounds = torch.stack([xlower_bounds, xupper_bounds])\n",
    "xbounds\n",
    "\n",
    "#convert numpy array to tensor  \n",
    "\n",
    "x = torch.tensor(df.iloc[:,:-1].values, dtype=torch.double)\n",
    "\n",
    "x = torch.tensor(df.iloc[:,:-1].values, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_tensor.shape torch.Size([100, 4])\n",
      "y_tensor.shape torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.double\n",
    "x_vals = df.iloc[:,:-1]\n",
    "x_tensors = torch.tensor(x_vals.values, dtype=dtype)\n",
    "\n",
    "print(f'x_tensor.shape',x_tensors.shape)\n",
    "\n",
    "y_tensors = torch.tensor(df.iloc[:,-1].values).unsqueeze(-1).double()\n",
    "print(f'y_tensor.shape',y_tensors.shape)\n",
    "\n",
    "x = normalize(x_tensors, bounds=xbounds)  \n",
    "y = standardize(y_tensors)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_candidates, x_test, y_candidates, y_test = train_test_split(x, y, test_size=0.30, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we set the bounds here from 0 being the min and 1 being the max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "mps_device = torch.device(\"cpu\")\n",
    "dtype = torch.double\n",
    "\n",
    "\n",
    "\n",
    "xtest = torch.tensor(x_test, device=mps_device, dtype=dtype)\n",
    "ytest = torch.tensor(y_test, device=mps_device, dtype=dtype)\n",
    "\n",
    "xcandidates_original = torch.tensor(x_candidates, device=mps_device, dtype=dtype)\n",
    "ycandidates_original = torch.tensor(y_candidates, device=mps_device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., dtype=torch.float64) tensor(1., dtype=torch.float64)\n",
      "tensor(0., dtype=torch.float64) tensor(1., dtype=torch.float64)\n",
      "tensor(0., dtype=torch.float64) tensor(1., dtype=torch.float64)\n",
      "tensor(0., dtype=torch.float64) tensor(1., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "lower_bound_mcp = []\n",
    "upper_bound_mcp = []\n",
    "for i in range(xcandidates_original.shape[1]):\n",
    "    print(xcandidates_original[:,i].min(), xcandidates_original[:,i].max())\n",
    "    lower_bound_val = xcandidates_original[:,i].min()\n",
    "    upper_bound_val = xcandidates_original[:,i].max()\n",
    "    \n",
    "    lower_bound_mcp.append(lower_bound_val)\n",
    "    upper_bound_mcp.append(upper_bound_val)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = torch.tensor([lower_bound_mcp, upper_bound_mcp], device='cpu', dtype=dtype)\n",
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "\n",
    "mcp = draw_sobol_samples(bounds=bounds, n=1024, q=1, seed=42).squeeze(1)\n",
    "mcp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function for random initial data points by percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to select random 5% of the data to be used as the initial training\n",
    "# set and remove it from the candidate set\n",
    "def random_initial_data(x, y, initial_percent, seed=i):\n",
    "    np.random.seed(seed)\n",
    "    n = int(x.shape[0]*initial_percent)\n",
    "    idx = np.random.choice(x.shape[0], n, replace=False)\n",
    "    x_initial = x[idx]\n",
    "    y_initial = y[idx]\n",
    "    x_candidates = np.delete(x, idx, axis=0)\n",
    "    y_candidates = np.delete(y, idx, axis=0)\n",
    "    return x_initial, y_initial, x_candidates, y_candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcandidates = xcandidates_original.clone()\n",
    "ycandidates = ycandidates_original.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28433119799187795"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp = SingleTaskGP(xcandidates, ycandidates) \n",
    "    # gp = SingleTaskGP(xinit, ytrain_,covar_module=rbf_kernel)\n",
    "mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "fit_gpytorch_mll(mll)\n",
    "#predict the y values for the test set\n",
    "ypred = gp(xtest)\n",
    "ypred_mean = ypred.mean.detach().numpy()\n",
    "# pred_y.append(ypred_mean)\n",
    "\n",
    "#calculate the mean absolute error and the standard deviation for the test set\n",
    "ymae = mean_absolute_error(ytest, ypred_mean)\n",
    "ymae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[913, 205, 2254, 2007, 1829, 1144, 840, 4468, 713, 4838, 3457, 261, 245, 768, 1792, 1906, 4140, 4932, 218, 4598, 1629, 4465, 3437, 1806, 3680]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set random seeds for 25 runs\n",
    "random.seed(42)\n",
    "seeds = [random.randint(1, 5000) for _ in range(25)]\n",
    "print(seeds)\n",
    "len(seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QNIPV function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:26<00:00,  2.52it/s]\n",
      "100%|██████████| 67/67 [00:26<00:00,  2.54it/s]\n",
      "100%|██████████| 67/67 [00:26<00:00,  2.49it/s]\n",
      "100%|██████████| 67/67 [00:27<00:00,  2.46it/s]\n",
      "100%|██████████| 67/67 [00:27<00:00,  2.44it/s]\n",
      "100%|██████████| 67/67 [00:28<00:00,  2.34it/s]\n",
      "100%|██████████| 67/67 [00:27<00:00,  2.47it/s]\n",
      "100%|██████████| 67/67 [00:27<00:00,  2.45it/s]\n",
      "100%|██████████| 67/67 [00:28<00:00,  2.38it/s]\n",
      "100%|██████████| 67/67 [00:28<00:00,  2.37it/s]\n",
      "100%|██████████| 67/67 [00:27<00:00,  2.40it/s]\n",
      "100%|██████████| 67/67 [00:26<00:00,  2.50it/s]\n",
      "100%|██████████| 67/67 [00:26<00:00,  2.54it/s]\n",
      "100%|██████████| 67/67 [00:27<00:00,  2.44it/s]\n",
      "100%|██████████| 67/67 [00:26<00:00,  2.52it/s]\n",
      "100%|██████████| 67/67 [00:26<00:00,  2.50it/s]\n",
      "100%|██████████| 67/67 [00:26<00:00,  2.50it/s]\n",
      "100%|██████████| 67/67 [00:27<00:00,  2.42it/s]\n",
      "100%|██████████| 67/67 [00:26<00:00,  2.49it/s]\n",
      "100%|██████████| 67/67 [00:26<00:00,  2.49it/s]\n",
      "100%|██████████| 67/67 [00:26<00:00,  2.49it/s]\n",
      "100%|██████████| 67/67 [00:26<00:00,  2.51it/s]\n",
      "100%|██████████| 67/67 [00:27<00:00,  2.46it/s]\n",
      "100%|██████████| 67/67 [00:27<00:00,  2.45it/s]\n",
      "100%|██████████| 67/67 [00:27<00:00,  2.45it/s]\n",
      "100%|██████████| 25/25 [11:20<00:00, 27.22s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# def qnipv_runs() -> list:\n",
    "\n",
    "rand_selection_mae = []\n",
    "xmax_candidates = []\n",
    "pred_mae = []\n",
    "pred_y = []\n",
    "pred_std = []\n",
    "qnipv_runs =[]\n",
    "\n",
    "def find_max_normalized_acqval(tensor_list, qNIVP):\n",
    "    max_value = None\n",
    "    max_index = -1\n",
    "    acq_val_lst = []\n",
    "    # torch.manual_seed(13)\n",
    "    for i, tensor_ in enumerate(tensor_list):\n",
    "        tensor = tensor_.unsqueeze(0)\n",
    "        qNIVP_val = qNIVP(tensor)\n",
    "        acq_val_lst.append(qNIVP_val.item())  # Assuming it's a scalar tensor\n",
    "\n",
    "        # Check if this is the maximum value so far\n",
    "        if max_value is None or qNIVP_val > max_value:\n",
    "            max_value = qNIVP_val\n",
    "            max_index = i\n",
    "\n",
    "    return max_value, max_index, acq_val_lst\n",
    "\n",
    "for i in tqdm(seeds):\n",
    "    xcandidates = xcandidates_original.clone()\n",
    "    ycandidates = ycandidates_original.clone()\n",
    "    xinit, yinit, xcandidates, ycandidates = random_initial_data(xcandidates, ycandidates, 0.05, seed=i)\n",
    "    gp = SingleTaskGP(xinit, yinit)\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    fit_gpytorch_mll(mll)\n",
    "    posterior = gp(xtest)\n",
    "    ypred = posterior.mean.detach().numpy()\n",
    "    ystd = posterior.stddev.detach().numpy()\n",
    "    \n",
    "    \n",
    "    # pred_y.append(ypred_mean)\n",
    "    ymae = mean_absolute_error(ytest, ypred)\n",
    "    \n",
    "    pred_mae = []\n",
    "    pred_y.append(ypred)\n",
    "    pred_std.append(ystd)\n",
    "    pred_mae.append(ymae)\n",
    "\n",
    "    for inner_i in tqdm(range(len(xcandidates))):\n",
    "        if not len(xcandidates):\n",
    "            break\n",
    "        \n",
    "        qNIVP = qNegIntegratedPosteriorVariance(gp, mc_points= mcp)\n",
    "        \n",
    "        \n",
    "        max_value, max_index, acq_val_lst = find_max_normalized_acqval(xcandidates, qNIVP)\n",
    "        xmax_candidates.append(max_index)\n",
    "        \n",
    "        xinit= torch.cat((xinit, xcandidates[max_index].unsqueeze(0)), 0)\n",
    "        yinit = torch.cat((yinit, ycandidates[max_index].unsqueeze(0)), 0)\n",
    "                    \n",
    "        xcandidates = torch.cat((xcandidates[:max_index], xcandidates[max_index + 1:]))\n",
    "        ycandidates = torch.cat((ycandidates[:max_index], ycandidates[max_index + 1:]))\n",
    "        \n",
    "        gp = SingleTaskGP(xinit, yinit) \n",
    "        # gp = SingleTaskGP(xinit, ytrain_,covar_module=rbf_kernel)\n",
    "        mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "        fit_gpytorch_mll(mll)\n",
    "        #predict the y values for the test set\n",
    "        ypred = gp(xtest)\n",
    "        ypred_mean = ypred.mean.detach().numpy()\n",
    "        pred_y.append(ypred_mean)\n",
    "\n",
    "        #calculate the mean absolute error and the standard deviation for the test set\n",
    "        ymae = mean_absolute_error(ytest, ypred_mean)\n",
    "        # print('mean absolute error: ', ymae)\n",
    "        pred_mae.append(ymae)\n",
    "        ystd = gp(xtest).stddev\n",
    "        ystd = ystd.detach().numpy()\n",
    "        pred_std.append(ystd)\n",
    "    qnipv_runs.append(pred_mae)\n",
    "    \n",
    "    # return qnipv_runs, gp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random selection function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_runs() -> list:\n",
    "\n",
    "    xcandidates_rand = xcandidates_original.clone()\n",
    "    ycandidates_rand = ycandidates_original.clone()\n",
    "\n",
    "    rand_xmax_candidates = []\n",
    "    rand_pred_mae = []\n",
    "    rand_pred_std = []\n",
    "    rand_pred_mean = []\n",
    "    random_mae_seeds =[]\n",
    "\n",
    "    for i in tqdm(seeds):\n",
    "       \n",
    "        xcandidates_rand = xcandidates_original.clone()\n",
    "        ycandidates_rand = ycandidates_original.clone()\n",
    "        xinit_rand, yinit_rand, xcandidates_rand, ycandidates_rand = random_initial_data(xcandidates_rand, ycandidates_rand, 0.05, seed=i)\n",
    "        \n",
    "        rand_xmax_candidates = []\n",
    "        rand_pred_mae = []\n",
    "        rand_pred_std = []\n",
    "        rand_pred_mean = []\n",
    "\n",
    "        gp = SingleTaskGP(xinit_rand, yinit_rand) \n",
    "        mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "        fit_gpytorch_mll(mll)\n",
    "        #predict the y values for the test set\n",
    "        rand_ypred = gp(xtest)\n",
    "        rand_ypred_mean = rand_ypred.mean.detach().numpy()\n",
    "        rand_pred_mean.append(rand_ypred_mean)\n",
    "        #calculate the mean absolute error and the standard deviation for the test set\n",
    "        rand_ymae = mean_absolute_error(ytest, rand_ypred_mean)\n",
    "        # print('mean absolute error: ', rand_ymae)\n",
    "        rand_pred_mae.append(rand_ymae)\n",
    "            \n",
    "        rand_ystd = gp(xtest).stddev\n",
    "        ystd_ = rand_ystd.detach().numpy()\n",
    "        rand_pred_std.append(ystd_)        \n",
    "        \n",
    "        for inner_i in tqdm(range(len(xcandidates_rand))):\n",
    "            if not len(xcandidates_rand):\n",
    "                break\n",
    "            \n",
    "            rand_select = random.randint(0, len(xcandidates_rand) - 1)\n",
    "            \n",
    "            # Add the selected tensor to the training sets\n",
    "            xinit_rand = torch.cat((xinit_rand, xcandidates_rand[rand_select].unsqueeze(0)), 0)\n",
    "            yinit_rand = torch.cat((yinit_rand, ycandidates_rand[rand_select].unsqueeze(0)), 0)\n",
    "            \n",
    "            xcandidates_rand = torch.cat((xcandidates_rand[:rand_select], xcandidates_rand[rand_select + 1:]))\n",
    "            ycandidates_rand = torch.cat((ycandidates_rand[:rand_select], ycandidates_rand[rand_select + 1:]))\n",
    "            \n",
    "            # Update GP model, fit and predict\n",
    "            gp = SingleTaskGP(xinit_rand, yinit_rand) \n",
    "            mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "            fit_gpytorch_mll(mll)\n",
    "            \n",
    "            # Predict the y values for the test set and calculate errors\n",
    "            rand_ypred = gp(xtest)\n",
    "            rand_ypred_mean = rand_ypred.mean.detach().numpy()\n",
    "            rand_pred_mean.append(rand_ypred_mean)\n",
    "            \n",
    "            rand_ymae = mean_absolute_error(ytest, rand_ypred_mean)\n",
    "            # print('mean absolute error: ', rand_ymae)\n",
    "            rand_pred_mae.append(rand_ymae)\n",
    "            \n",
    "            rand_ystd = gp(xtest).stddev\n",
    "            ystd_ = rand_ystd.detach().numpy()\n",
    "            rand_pred_std.append(ystd_)\n",
    "        random_mae_seeds.append(rand_pred_mae)\n",
    "    return random_mae_seeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:06<00:00,  9.79it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 13.31it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 12.33it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00, 10.79it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00, 10.85it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00, 10.54it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 12.91it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 11.38it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 11.62it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00,  9.61it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 12.73it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00, 10.27it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 11.92it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00,  9.87it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 12.38it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 12.02it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 12.95it/s]\n",
      "100%|██████████| 67/67 [00:04<00:00, 14.42it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 12.25it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 11.29it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 12.96it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 12.78it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 11.87it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00, 10.21it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 11.68it/s]\n",
      "100%|██████████| 25/25 [02:25<00:00,  5.81s/it]\n"
     ]
    }
   ],
   "source": [
    "random_runs_second_run = random_runs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QBC FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def qbc_runs() -> list:\n",
    "    gp_commit_lst = []\n",
    "    committee = [\n",
    "        RandomForestRegressor(),\n",
    "        SVR(),\n",
    "        DecisionTreeRegressor()\n",
    "    ]\n",
    "\n",
    "    comit_pred_mae = []\n",
    "    commit_seeds = []\n",
    "\n",
    "    for i in tqdm(seeds):\n",
    "        \n",
    "        xcandidates_comit = xcandidates_original.clone()\n",
    "        ycandidates_comit = ycandidates_original.clone()\n",
    "        xinit_comit, yinit_comit, xcandidates_comit, ycandidates_comit = random_initial_data(xcandidates_comit, ycandidates_comit, 0.05, seed=i)\n",
    "        gp_commit_lst = []\n",
    "        \n",
    "        \n",
    "        gp = SingleTaskGP(xinit_comit, yinit_comit)\n",
    "        mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "        fit_gpytorch_mll(mll)\n",
    "        posterior = gp(xtest)\n",
    "        ypred = posterior.mean.detach().numpy()\n",
    "        \n",
    "        comitt_ymae = mean_absolute_error(ytest, ypred)\n",
    "        gp_commit_lst.append(comitt_ymae)\n",
    "        for inner_i in tqdm(range(len(xcandidates_comit))):\n",
    "            if not len(xcandidates_comit):\n",
    "                print('empty')\n",
    "                break\n",
    "            # print(f'this is {i}')\n",
    "            for model in committee:\n",
    "                model.fit(xinit_comit, yinit_comit)\n",
    "\n",
    "            predictions = np.array([model.predict(xcandidates_comit) for model in committee])\n",
    "\n",
    "        \n",
    "            disagreement_scores = np.var(predictions, axis=0)\n",
    "\n",
    "            N = 1  \n",
    "            top_N_indices = np.argsort(disagreement_scores)[-N:]\n",
    "\n",
    "            X_to_query = xcandidates_comit[top_N_indices]\n",
    "            \n",
    "            ylabel = ycandidates_comit[top_N_indices]\n",
    "            \n",
    "            xinit_comit = torch.cat((xinit_comit, X_to_query), 0)\n",
    "            yinit_comit = torch.cat((yinit_comit, ylabel), 0)\n",
    "            \n",
    "            xcandidates_comit = torch.cat((xcandidates_comit[:int(top_N_indices)], xcandidates_comit[int(top_N_indices) + 1:]))\n",
    "            # print(f'len of x candidates: {len(xcandidates_comit)}')\n",
    "            ycandidates_comit = torch.cat((ycandidates_comit[:int(top_N_indices)], ycandidates_comit[int(top_N_indices) + 1:]))\n",
    "            \n",
    "            \n",
    "            gp = SingleTaskGP(xinit_comit, yinit_comit)\n",
    "            mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "            fit_gpytorch_mll(mll)\n",
    "            posterior = gp(xtest)\n",
    "            ypred = posterior.mean.detach().numpy()\n",
    "                \n",
    "            comitt_ymae = mean_absolute_error(ytest, ypred)\n",
    "            gp_commit_lst.append(comitt_ymae)\n",
    "            # print(f'length of gp_commit_lst: {len(gp_commit_lst)}')\n",
    "        commit_seeds.append(gp_commit_lst)\n",
    "        \n",
    "        \n",
    "    return commit_seeds    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:07<00:00,  8.46it/s]\n",
      "100%|██████████| 67/67 [00:07<00:00,  9.36it/s]\n",
      "100%|██████████| 67/67 [00:07<00:00,  9.17it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00,  9.73it/s]\n",
      "100%|██████████| 67/67 [00:07<00:00,  9.26it/s]\n",
      "100%|██████████| 67/67 [00:07<00:00,  8.60it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00, 10.68it/s]\n",
      "100%|██████████| 67/67 [00:07<00:00,  9.15it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00,  9.98it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00,  9.61it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00, 10.56it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00,  9.79it/s]\n",
      "100%|██████████| 67/67 [00:07<00:00,  9.56it/s]\n",
      "100%|██████████| 67/67 [00:07<00:00,  9.03it/s]\n",
      "100%|██████████| 67/67 [00:07<00:00,  9.44it/s]\n",
      "100%|██████████| 67/67 [00:07<00:00,  9.25it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00, 10.62it/s]\n",
      "100%|██████████| 67/67 [00:07<00:00,  9.55it/s]\n",
      "100%|██████████| 67/67 [00:07<00:00,  8.59it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00,  9.67it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00, 10.12it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00, 10.37it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00,  9.85it/s]\n",
      "100%|██████████| 67/67 [00:07<00:00,  8.93it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00, 10.07it/s]\n",
      "100%|██████████| 25/25 [02:56<00:00,  7.05s/it]\n"
     ]
    }
   ],
   "source": [
    "qbc_runs = qbc_runs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('AM_qbc_runs.npy', np.array(qbc_runs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainty Sampling Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def uncertainty_runs() -> list:\n",
    "    torch.manual_seed(13)\n",
    "    \n",
    "    uncr_xmax_candidates = []\n",
    "    uncr_pred_mae = []\n",
    "    uncr_pred_std = []\n",
    "    uncr_pred_mean = []\n",
    "    unc_rand_mae_seeds = []\n",
    "\n",
    "    for i in seeds:        \n",
    "        xcandidates_uncr = xcandidates_original.clone()\n",
    "        ycandidates_uncr = ycandidates_original.clone()\n",
    "        xinit_uncr, yinit_uncr, xcandidates_uncr, ycandidates_uncr = random_initial_data(xcandidates_uncr, ycandidates_uncr, 0.05, seed=i)\n",
    "        \n",
    "        uncr_xmax_candidates = []\n",
    "        uncr_pred_mae = []\n",
    "        uncr_pred_std = []\n",
    "        uncr_pred_mean = []\n",
    "\n",
    "        gp = SingleTaskGP(xinit_uncr, yinit_uncr)\n",
    "        mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "        fit_gpytorch_mll(mll)\n",
    "\n",
    "        uncr_ypred = gp(xtest)\n",
    "        uncr_ypred_mean = uncr_ypred.mean.detach().numpy()\n",
    "        uncr_pred_mean.append(uncr_ypred_mean)\n",
    "        \n",
    "        uncr_ymae = mean_absolute_error(ytest, uncr_ypred_mean)\n",
    "        uncr_pred_mae.append(uncr_ymae)\n",
    "        \n",
    "        uncr_ystd = gp(xtest).stddev.detach().numpy()\n",
    "        uncr_pred_std.append(uncr_ystd)\n",
    "\n",
    "        # Active learning loop (25 iterations)\n",
    "        for inner_i in tqdm(range(len(xcandidates_uncr))):\n",
    "            if not len(xcandidates_uncr):\n",
    "                print('empty')\n",
    "                break\n",
    "            posterior_candidates = gp(xcandidates_uncr)\n",
    "            uncertainties = posterior_candidates.stddev.detach().numpy() \n",
    "            max_uncertainty_idx = uncertainties.argmax()\n",
    "\n",
    "            xinit_uncr = torch.cat((xinit_uncr, xcandidates_uncr[max_uncertainty_idx].unsqueeze(0)), 0)\n",
    "            yinit_uncr = torch.cat((yinit_uncr, ycandidates_uncr[max_uncertainty_idx].unsqueeze(0)), 0)\n",
    "            \n",
    "            xcandidates_uncr = torch.cat((xcandidates_uncr[:max_uncertainty_idx], xcandidates_uncr[max_uncertainty_idx + 1:]))\n",
    "            ycandidates_uncr = torch.cat((ycandidates_uncr[:max_uncertainty_idx], ycandidates_uncr[max_uncertainty_idx + 1:]))\n",
    "\n",
    "            # Retrain the GP model on the updated training set\n",
    "            gp = SingleTaskGP(xinit_uncr, yinit_uncr)\n",
    "            mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "            fit_gpytorch_mll(mll)\n",
    "\n",
    "            # Predict the y values for the test set\n",
    "            uncr_ypred = gp(xtest)\n",
    "            uncr_ypred_mean = uncr_ypred.mean.detach().numpy()\n",
    "            uncr_pred_mean.append(uncr_ypred_mean)\n",
    "\n",
    "            # Calculate the mean absolute error (MAE) for the test set\n",
    "            uncr_ymae = mean_absolute_error(ytest, uncr_ypred_mean)\n",
    "            # print(f'Iteration {i}: mean absolute error = {uncr_ymae}')\n",
    "            uncr_pred_mae.append(uncr_ymae)\n",
    "\n",
    "            uncr_ystd = gp(xtest).stddev.detach().numpy()\n",
    "            uncr_pred_std.append(uncr_ystd)\n",
    "\n",
    "        unc_rand_mae_seeds.append(uncr_pred_mae)\n",
    "    return unc_rand_mae_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:06<00:00, 10.77it/s]\n",
      "100%|██████████| 67/67 [00:07<00:00,  9.10it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00, 10.99it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00,  9.98it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 13.11it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00, 10.06it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00,  9.87it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 11.53it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 11.67it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 11.55it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 12.21it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00, 10.76it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 13.35it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 11.92it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00, 10.81it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 12.82it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 12.98it/s]\n",
      "100%|██████████| 67/67 [00:04<00:00, 13.97it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 13.15it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 13.10it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 12.04it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 11.81it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 11.64it/s]\n",
      "100%|██████████| 67/67 [00:05<00:00, 11.56it/s]\n",
      "100%|██████████| 67/67 [00:06<00:00, 10.77it/s]\n"
     ]
    }
   ],
   "source": [
    "uncertainty_runs = uncertainty_runs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('AM_uncertainty_runs.npy', np.array(uncertainty_runs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qbc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
