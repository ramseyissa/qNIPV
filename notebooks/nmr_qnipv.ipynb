{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional\n",
    "import torch\n",
    "import random\n",
    "import os \n",
    "import argparse\n",
    "from typing import (\n",
    "    Any,\n",
    "    Callable,\n",
    "    Dict,\n",
    "    Hashable,\n",
    "    Iterable,\n",
    "    List,\n",
    "    Optional,\n",
    "    Sequence,\n",
    "    Tuple,\n",
    "    Type,\n",
    "    TypeVar,\n",
    "    Union,\n",
    ")\n",
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from botorch.models.gp_regression import SingleTaskGP\n",
    "from tqdm import tqdm\n",
    "from torch import Tensor\n",
    "from botorch.acquisition.active_learning import (\n",
    "    MCSampler,\n",
    "    qNegIntegratedPosteriorVariance,\n",
    ")\n",
    "\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from sklearn.model_selection import train_test_split\n",
    "from botorch.models.gp_regression import SingleTaskGP\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import gc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import warnings\n",
    "\n",
    "import pickle\n",
    "\n",
    "from botorch.exceptions.warnings import BotorchTensorDimensionWarning, InputDataWarning\n",
    "warnings.filterwarnings(\n",
    "            \"ignore\",\n",
    "            message=\"Input data is not standardized.\",\n",
    "            category=InputDataWarning,\n",
    "        )\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "from botorch.models.fully_bayesian import SaasFullyBayesianSingleTaskGP\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "from botorch.acquisition.active_learning import (\n",
    "    MCSampler,\n",
    "    qNegIntegratedPosteriorVariance,\n",
    ")\n",
    "\n",
    "from botorch.utils.transforms import normalize, standardize\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# dtype = torch.double\n",
    "dtype = torch.float32\n",
    "\n",
    "\n",
    "# Ensure output directory exists\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "bounds = torch.tensor([[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]], device=device, dtype=dtype)\n",
    "\n",
    "mcp = draw_sobol_samples(bounds=bounds, n=1024, q=1, seed=42).squeeze(1)\n",
    "mcp.to(device=device, dtype=dtype)\n",
    "# bounds\n",
    "\n",
    "\n",
    "seeds = np.load('seeds.npy')\n",
    "xtest = np.load('xtest.npy')\n",
    "ytest = np.load('ytest.npy')\n",
    "\n",
    "\n",
    "with open('xcandidates_original.pkl', 'rb') as f:\n",
    "    xcandidates_original = pickle.load(f)\n",
    "    \n",
    "with open('ycandidates_original.pkl', 'rb') as f:\n",
    "    ycandidates_original = pickle.load(f)\n",
    "    \n",
    "xtest = torch.tensor(xtest, dtype=dtype,device=device)\n",
    "ytest = torch.tensor(ytest, dtype=dtype,device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 25 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [19:48<00:00, 11.88s/it]\n",
      "  4%|▍         | 1/25 [19:48<7:55:17, 1188.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 1037 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [19:14<00:00, 11.55s/it]\n",
      "  8%|▊         | 2/25 [39:03<7:28:09, 1169.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 2545 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [19:24<00:00, 11.64s/it]\n",
      " 12%|█▏        | 3/25 [58:28<7:07:52, 1166.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 996 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [20:21<00:00, 12.22s/it]\n",
      " 16%|█▌        | 4/25 [1:18:50<6:56:02, 1188.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 3343 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [19:17<00:00, 11.58s/it]\n",
      " 20%|██        | 5/25 [1:38:08<6:32:31, 1177.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 2470 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [19:40<00:00, 11.80s/it]\n",
      " 24%|██▍       | 6/25 [1:57:48<6:13:11, 1178.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 2204 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [20:19<00:00, 12.19s/it]\n",
      " 28%|██▊       | 7/25 [2:18:07<5:57:33, 1191.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 4629 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [20:19<00:00, 12.20s/it]\n",
      " 32%|███▏      | 8/25 [2:38:27<5:40:14, 1200.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 4893 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [53:36<00:00, 32.17s/it]\n",
      " 36%|███▌      | 9/25 [3:32:04<8:08:16, 1831.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 635 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:50:03<00:00, 66.03s/it] \n",
      " 40%|████      | 10/25 [5:22:07<13:46:04, 3304.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 3850 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:31:38<00:00, 54.98s/it]\n",
      " 44%|████▍     | 11/25 [6:53:46<15:27:41, 3975.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 4277 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [34:23<00:00, 20.64s/it]\n",
      " 48%|████▊     | 12/25 [7:28:10<12:15:25, 3394.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 3004 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:59:59<00:00, 72.00s/it] \n",
      " 52%|█████▏    | 13/25 [9:28:10<15:09:25, 4547.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 294 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [27:32<00:00, 16.52s/it]\n",
      " 56%|█████▌    | 14/25 [9:55:43<11:13:22, 3672.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 47 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [29:48<00:00, 17.88s/it]\n",
      " 60%|██████    | 15/25 [10:25:31<8:37:28, 3104.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 2619 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [51:48<00:00, 31.08s/it]\n",
      " 64%|██████▍   | 16/25 [11:17:20<7:45:55, 3106.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 2743 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [35:21<00:00, 21.22s/it]\n",
      " 68%|██████▊   | 17/25 [11:52:42<6:14:42, 2810.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 1271 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [19:46<00:00, 11.86s/it]\n",
      " 72%|███████▏  | 18/25 [12:12:29<4:30:56, 2322.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 4068 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [20:04<00:00, 12.04s/it]\n",
      " 76%|███████▌  | 19/25 [12:32:33<3:18:39, 1986.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 4586 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [19:54<00:00, 11.95s/it]\n",
      " 80%|████████  | 20/25 [12:52:28<2:25:44, 1748.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 4365 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [19:51<00:00, 11.91s/it]\n",
      " 84%|████████▍ | 21/25 [13:12:20<1:45:26, 1581.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 4233 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [19:35<00:00, 11.76s/it]\n",
      " 88%|████████▊ | 22/25 [13:31:55<1:12:59, 1459.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 3885 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [20:09<00:00, 12.09s/it]\n",
      " 92%|█████████▏| 23/25 [13:52:05<46:09, 1384.65s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 1828 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [20:58<00:00, 12.58s/it]\n",
      " 96%|█████████▌| 24/25 [14:13:03<22:26, 1346.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running seed 1698 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [19:01<00:00, 11.42s/it]\n",
      "100%|██████████| 25/25 [14:32:05<00:00, 2093.03s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def random_initial_data(x, y, initial_percent, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    # np.random.seed(seed)\n",
    "    n = int(len(x)*initial_percent)\n",
    "    idx = np.random.choice(len(x), n, replace=False).tolist()\n",
    "    x_initial = [x[i] for i in idx]\n",
    "    y_initial = [y[i] for i in idx]\n",
    "    xcandidates = [x[i] for i in range(len(x)) if i not in idx]\n",
    "    ycandidates = [y[i] for i in range(len(y)) if i not in idx]\n",
    "    \n",
    "    return x_initial, y_initial, xcandidates, ycandidates\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rand_selection_mae = []\n",
    "xmax_candidates = []\n",
    "pred_mae = []\n",
    "pred_y = []\n",
    "pred_std = []\n",
    "qnipv_runs =[]\n",
    "\n",
    "\n",
    "\n",
    "def find_max_normalized_acqval(tensor_list, qNIVP):\n",
    "    max_value = None\n",
    "    max_index = -1\n",
    "    acq_val_lst = []\n",
    "    # torch.manual_seed(13)\n",
    "    for i, tensor in enumerate(tensor_list):\n",
    "        tensor_len = len(tensor)\n",
    "        qNIVP_val = qNIVP(tensor)\n",
    "        normalized_qNIVP_val = qNIVP_val / tensor_len\n",
    "        acq_val_lst.append(normalized_qNIVP_val.item())\n",
    "        if max_value is None or normalized_qNIVP_val > max_value:\n",
    "            max_value = normalized_qNIVP_val\n",
    "            max_index = i\n",
    "\n",
    "    return max_value, max_index, acq_val_lst\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm(seeds):\n",
    "    print(f'running seed {i} of {len(seeds)}')\n",
    "    torch.cuda.empty_cache()\n",
    "    xcandidates = xcandidates_original.copy()\n",
    "    ycandidates = ycandidates_original.copy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    xinit, yinit, xcandidates, ycandidates = random_initial_data(xcandidates, ycandidates, 0.05, seed=i)\n",
    "    \n",
    "    \n",
    "    xinit = torch.cat(xinit,dim=0).to(device)\n",
    "    yinit = torch.cat(yinit,dim=0).to(device)\n",
    "\n",
    "    \n",
    "    gp = SingleTaskGP(xinit, yinit).to(device)\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp).to(device)\n",
    "    fit_gpytorch_mll(mll)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        posterior = gp(xtest)\n",
    "        ypred = posterior.mean.detach().cpu().numpy()\n",
    "        # ystd = posterior.stddev.detach().cpu().numpy()\n",
    "        del posterior\n",
    "    \n",
    "    # posterior = gp(xtest)\n",
    "    # ypred = posterior.mean.detach().numpy()\n",
    "    # ystd = posterior.stddev.detach().numpy()\n",
    "    \n",
    "    \n",
    "    ymae = mean_absolute_error(ytest, ypred)\n",
    "    \n",
    "    pred_mae = []\n",
    "    # pred_y.append(ypred)\n",
    "    # pred_std.append(ystd)\n",
    "    pred_mae.append(ymae)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for inner_i in tqdm(range(100)):\n",
    "        if not len(xcandidates):\n",
    "            break\n",
    "        \n",
    "        qNIVP = qNegIntegratedPosteriorVariance(gp, mc_points= mcp)\n",
    "        \n",
    "        \n",
    "        max_value, max_index, acq_val_lst = find_max_normalized_acqval(xcandidates, qNIVP)\n",
    "        xmax_candidates.append(max_index)\n",
    "        \n",
    "        # print(f'pre-addtion of new ten',len(xinit))\n",
    "        xinit= torch.cat((xinit, xcandidates[max_index]), 0).to(device)\n",
    "        yinit = torch.cat((yinit, ycandidates[max_index]), 0).to(device)\n",
    "        \n",
    "        \n",
    "        del xcandidates[max_index]\n",
    "        del ycandidates[max_index]\n",
    "        \n",
    "        del gp, mll\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "       \n",
    "        \n",
    "        gp = SingleTaskGP(xinit, yinit).to(device)\n",
    "        # gp = SingleTaskGP(xinit, ytrain_,covar_module=rbf_kernel)\n",
    "        mll = ExactMarginalLogLikelihood(gp.likelihood, gp).to(device)\n",
    "        fit_gpytorch_mll(mll)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            ypred = gp(xtest)\n",
    "            ypred_mean = ypred.mean.detach().numpy()\n",
    "            del ypred\n",
    "            \n",
    "            # pred_y.append(ypred_mean)\n",
    "\n",
    "            ymae = mean_absolute_error(ytest, ypred_mean)\n",
    "        # print('mean absolute error: ', ymae)\n",
    "            pred_mae.append(ymae)\n",
    "        # ystd = gp(xtest).stddev\n",
    "        # ystd = ystd.detach().numpy()\n",
    "        # pred_std.append(ystd)\n",
    "    qnipv_runs.append(pred_mae)\n",
    "    # np.save('qnipv_runs_copy.npy', np.array(qnipv_runs))\n",
    "    np.save('qnipv_runs_seed.npy', np.array(pred_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('qnipv_runs_seed_true.npy', np.array(qnipv_runs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qbc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
